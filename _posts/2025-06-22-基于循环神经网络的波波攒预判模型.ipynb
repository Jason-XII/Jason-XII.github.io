{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba6ed8d2-786a-4c10-a06f-f2418c93339b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "Bor-bor-zan is a famous game played at my high school *bdyz*. I won't explain the rules here for simplicity, but note that the game has eight basic moves, and the two players produce their moves at the same time. The game can end when a deadly move strikes one player, which can happen on the first move, or after an arbitrary number of moves. \n",
    "I want to train a model to recognize the game's rules and predict the two players' next moves.\n",
    "# Preparing the data\n",
    "## Defining the rules\n",
    "I've created a class that can fully represent the game of bor-bor-zan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d574038a-c8c8-442a-bb06-692d0f1c63b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "class Game:\n",
    "    def __init__(self):\n",
    "        self.winner = 0\n",
    "        self.e1 = 0 # energy of player 1, etc.\n",
    "        self.e2 = 0\n",
    "        self.over = False # the game is still on\n",
    "        self.requires = [0, 0, 0, 1, 1, 0, 1, 3, 2]\n",
    "        self.text = [0, \"zan\", \"shield\", \"shoot\", \"reflect\", \"buddha\", \"steal\", \"chick\", \"big-shield\"]\n",
    "        self.record = []\n",
    "    def act(self, action1, action2):\n",
    "        # 1：攒豆；2：盾；3：枪；4：鄙视；5：拜佛；6：爱心；7：鸡！8：大盾\n",
    "        # determine if the game is still on\n",
    "        if self.determine(action1, action2):\n",
    "            # player 1 wins\n",
    "            self.over = True\n",
    "            self.winner = 1\n",
    "        elif self.determine(action2, action1):\n",
    "            self.over = True\n",
    "            self.winner = 2\n",
    "        if action1 == 1:\n",
    "            self.e1 += 1\n",
    "        elif action1 in [3, 4, 6]:\n",
    "            self.e1 -= 1\n",
    "        elif action1 == 7:\n",
    "            self.e1 -= 3\n",
    "        elif action1 == 8:\n",
    "            self.e1 -= 2\n",
    "        if action2 == 1:\n",
    "            self.e2 += 1\n",
    "        elif action2 in [3, 4, 6]:\n",
    "            self.e2 -= 1\n",
    "        elif action2 == 7:\n",
    "            self.e2 -= 3\n",
    "        elif action2 == 8:\n",
    "            self.e2 -= 2\n",
    "        # 特判拜佛、爱心\n",
    "        # 如果有一方拜佛而且没有死，那么对方豆肯定被清空。对拜同理。\n",
    "        if action1 == 5:\n",
    "            self.e2 = 0\n",
    "        if action2 == 5:\n",
    "            self.e1 = 0\n",
    "        # 如果双方同时出爱心，则对撞，不产生效果\n",
    "        if action1==6 and action2==6:\n",
    "            return\n",
    "        if action1==6 and action2!=5:\n",
    "            self.e1+=self.e2\n",
    "            self.e2 = 0\n",
    "        if action2==6 and action1!=5:\n",
    "            self.e2+=self.e1\n",
    "            self.e1 = 0\n",
    "        self.record.append((self.text[action1], self.text[action2]))\n",
    "    def determine(self, act1, act2):\n",
    "        # 不分顺序，看看1是否能将2打死\n",
    "        if act1 == 2 and act2 == 5: return True # 拜佛拜死\n",
    "        if act1 == 3 and (act2 in [1, 5, 6, 8]): return True # 开枪打死\n",
    "        if act1 == 4 and act2 == 3: return True # 反弹\n",
    "        if act1 == 5 and act2 == 4: return True # 鄙视佛祖\n",
    "        if act1 == 7 and act2 <= 6: return True # 鸡无敌\n",
    "        if act1 == 8 and act2 == 5: return True # 大盾秀\n",
    "        return False\n",
    "    def pretty_record(self):\n",
    "        return list((self.text[a], self.text[b]) for (a,b) in self.record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f0323-3cff-4b03-9a1f-8e159ec18e9f",
   "metadata": {},
   "source": [
    "To show usage of the class I defined above, here's a demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97bd6d22-a1f5-42cb-ad83-771f9f41e1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 2\n"
     ]
    }
   ],
   "source": [
    "game = Game()\n",
    "buddha, shield = game.text.index('buddha'), game.text.index('shield')\n",
    "game.act(buddha, shield)\n",
    "print(game.over, game.winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c65ed-8de8-4270-bcb7-3b58ef66d13f",
   "metadata": {},
   "source": [
    "Basically, after creating a `Game` instance, you can use the `act` method to pass in the moves each player had chosen. After `act` was called, the `over` and `winner` properties will be updated to show whether the game has ended, and the winner of the game. But beware that this class doesn't check for illegal moves. To fix it, we define another class that inherits from `Game`, creating a basic program that generates random outputs in a possible situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e04706f-dc38-4c00-b698-bfabae93aaff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GameAI(Game):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 此时机器作为player2\n",
    "    def act(self, action1):\n",
    "        actions_available = [i for i in range(1, 9) if self.requires[i]<=self.e2]\n",
    "        act = random.choice(actions_available)   \n",
    "        super().act(action1, act)\n",
    "        return act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aae88d-d1d5-47f7-9210-04d8fc9ef217",
   "metadata": {},
   "source": [
    "Now let's test it to see which move it produces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "902ce07d-5508-48ae-afc4-d2030e3156fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shield'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = GameAI()\n",
    "game.text[game.act(game.text.index('zan'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab742918-7213-42b3-84c7-bd7fe3bf6ec1",
   "metadata": {},
   "source": [
    "So the supposed AI is working properly, sticking to the game's rules. It's time to generate some game data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057477aa-e29f-4320-be03-da1afc22333a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating game data\n",
    "You might have noticed that the GameAI only generates a possible action for player 2. To fix that, we will need an algorithm to generate possible actions for both two players. So I defined a new class, `DataGen` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e676d18-1772-4aa5-ba80-f9f38d5754f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGen(Game):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.text_record = []\n",
    "        \n",
    "    def act(self):\n",
    "        actions_available_1 = [i for i in range(1, 9) if self.requires[i]<=self.e1]\n",
    "        actions_available_2 = [i for i in range(1, 9) if self.requires[i]<=self.e2]\n",
    "        act_combination = random.choice(actions_available_1), random.choice(actions_available_2)\n",
    "        super().act(*act_combination)\n",
    "        text = self.text[act_combination[0]], self.text[act_combination[1]]\n",
    "        self.text_record.append(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf70555-5bdc-42a6-9c41-a60c894da395",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab44290-5499-41e0-836e-f9c0d75c3892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('shield', 'buddha')]\n"
     ]
    }
   ],
   "source": [
    "game = DataGen()\n",
    "while not game.over:\n",
    "    game.act()\n",
    "print(game.text_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a84aa5-a276-4540-a11b-76801b50e7c5",
   "metadata": {},
   "source": [
    "Now lets generate 100,000 game records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda51d14-f1cf-460d-84e0-ef579b8aa2c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_one_rec():\n",
    "    game = DataGen()\n",
    "    while not game.over:\n",
    "        game.act()\n",
    "    return game.text_record\n",
    "\n",
    "data = []\n",
    "for i in range(100000):\n",
    "    data.append(get_one_rec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f345b5c5-d4ef-4c63-8907-40ffd31a3eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('zan', 'buddha'),\n",
       "  ('zan', 'buddha'),\n",
       "  ('buddha', 'zan'),\n",
       "  ('shield', 'shield'),\n",
       "  ('buddha', 'buddha'),\n",
       "  ('buddha', 'zan'),\n",
       "  ('buddha', 'shield')],\n",
       " [('buddha', 'buddha'), ('shield', 'shield'), ('buddha', 'shield')],\n",
       " [('shield', 'buddha')],\n",
       " [('shield', 'buddha')],\n",
       " [('buddha', 'buddha'), ('buddha', 'shield')]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fdb849-9140-4e1f-8122-8e4b62047607",
   "metadata": {},
   "source": [
    "It takes a really short time to generate all these data! We now need to concatenate this list to a document, for feeding into our language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d54b2f-f3d3-4622-8f34-1adc3378ccd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lst_to_doc(lst):\n",
    "    stream = ''\n",
    "    for each in lst:\n",
    "        stream += ' to '.join(each)+' , '\n",
    "    stream += 'end . '\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad619f99-8f77-4d80-9ae9-0b8ce2fbaa8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buddha to zan , buddha to zan , zan to zan , buddha to shoot , end . '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_to_doc([('buddha', 'zan'), ('buddha', 'zan'), ('zan', 'zan'), ('buddha', 'shoot')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e6cd5-5130-480e-bd20-f9e0b5251c06",
   "metadata": {},
   "source": [
    "We can therefore map this function to all the items in our 100,000 items long list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d643aa35-2b52-449a-8287-263ecd631565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for each in data:\n",
    "    documents.append(lst_to_doc(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0515f9a-efa7-46fd-bcc0-c9fe45862b08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zan to buddha , zan to buddha , buddha to zan , shield to shield , buddha to buddha , buddha to zan , buddha to shield , end . ',\n",
       " 'buddha to buddha , shield to shield , buddha to shield , end . ',\n",
       " 'shield to buddha , end . ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07964fe-e787-4946-abe7-7d0b9f3183cd",
   "metadata": {},
   "source": [
    "Splitting the dataset and joining the documents together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71145d63-052f-42e8-a60c-478eda9a964c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_document = ''.join(documents[:80000])\n",
    "valid_document = ''.join(documents[80000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "996fd9c5-5b8f-4299-9b76-e4a8e410bfea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eld to shield , zan to buddha , buddha to buddha , zan to buddha , shield to shield , buddha to shie'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_document[900: 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da074c3-068e-4a87-8775-0c6f2f9017ec",
   "metadata": {},
   "source": [
    "Seems right!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3521e33-b235-422c-99dd-d237af375ab6",
   "metadata": {},
   "source": [
    "## Tokenization and Numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f05f9f3-8428-4ecc-b83e-ecefa1d7fd41",
   "metadata": {},
   "source": [
    "First we import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e05f3f27-1b2e-4d53-ae7d-82b3d49e088d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e048f3a-17ef-4cea-957d-8d4e81036fc8",
   "metadata": {},
   "source": [
    "Then we split the document and turn that into corresponding indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50459d59-052b-428f-8f0a-c64c488cea62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zan', 'to', 'buddha', ',', 'zan', 'to', 'buddha', ',', 'buddha', 'to']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = train_document.split(' ')\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bc2888b-e35b-4cdb-8458-d5a94bd41396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#13) ['zan','to','buddha',',','shield','end','.','shoot','steal','reflect','chick','big-shield','']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = L(*tokens).unique()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "538edd8e-c3cc-46db-a7aa-5b60df028728",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1435321) [0,1,2,3,0,1,2,3,2,1,0,3,4,1,4,3,2,1,2,3...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = {w:i for i,w in enumerate(vocab)}\n",
    "nums = L(word2idx[i] for i in tokens)\n",
    "nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89edaa1d-24ac-469b-994b-32dfc4322166",
   "metadata": {},
   "source": [
    "Now do the same thing with the validation document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "164c46bb-c9f2-4bc7-a9dc-632c1ba085f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens_v = valid_document.split(' ')\n",
    "nums_v = L(word2idx[i] for i in tokens_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b86fd9-eb8e-4575-a1ae-27b4475b7aad",
   "metadata": {},
   "source": [
    "## Creating the Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c99ee8d-50c1-4101-bfc8-fdfcbbebfb3d",
   "metadata": {},
   "source": [
    "We want the model to predict the next token based on the previous three tokens. I know that's clearly not enough, but for simplicity of code, we'll have to temporarily endure this inconvenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0451bd65-b036-4a5b-924e-2297769bc20c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#239219) [(tensor([0, 1, 2, 3, 0, 1]), 2),(tensor([2, 3, 2, 1, 0, 3]), 4),(tensor([4, 1, 4, 3, 2, 1]), 2),(tensor([2, 3, 2, 1, 0, 3]), 2),(tensor([2, 1, 4, 3, 5, 6]), 2),(tensor([2, 1, 2, 3, 4, 1]), 4),(tensor([4, 3, 2, 1, 4, 3]), 5),(tensor([5, 6, 4, 1, 2, 3]), 5),(tensor([5, 6, 4, 1, 2, 3]), 5),(tensor([5, 6, 2, 1, 2, 3]), 2),(tensor([2, 1, 4, 3, 5, 6]), 0),(tensor([0, 1, 0, 3, 2, 1]), 7),(tensor([7, 3, 5, 6, 2, 1]), 2),(tensor([2, 3, 0, 1, 0, 3]), 8),(tensor([8, 1, 8, 3, 2, 1]), 4),(tensor([4, 3, 5, 6, 2, 1]), 0),(tensor([0, 3, 2, 1, 2, 3]), 0),(tensor([0, 1, 2, 3, 0, 1]), 4),(tensor([4, 3, 0, 1, 0, 3]), 2),(tensor([2, 1, 7, 3, 5, 6]), 0)...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = L((tensor(nums[i:i+6]), nums[i+6]) for i in range(0,len(nums)-7,6))\n",
    "seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610271e-ab5b-4b0a-830c-f970c10d311b",
   "metadata": {},
   "source": [
    "The same with the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c198409-8f86-48a8-941a-4deeccba89d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seqs_v = L((tensor(nums_v[i:i+6]), nums_v[i+6]) for i in range(0,len(nums_v)-7,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e4fa0d0-6349-4a32-a446-b69e2f029aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 128\n",
    "dls = DataLoaders.from_dsets(seqs, seqs_v, bs=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c10ba5-be3a-41e1-885b-32e500634a8e",
   "metadata": {},
   "source": [
    "## A simple recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b18394a6-f69b-45e3-a1bb-b9461cac259e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel1(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.h_h(self.i_h(x[:,0])))\n",
    "        h = h + self.i_h(x[:,1])\n",
    "        h = F.relu(self.h_h(h))\n",
    "        h = h + self.i_h(x[:,2])\n",
    "        h = F.relu(self.h_h(h))\n",
    "        return self.h_o(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0040f8-75e0-4441-bbfa-b41c327f432d",
   "metadata": {},
   "source": [
    "Let me explain what the code above means. `i_h` means input to hidden layer, which is specified as an embedding layer - that basically does an accelerated indexing process. `h_h` means hidden to hidden layer, adding the nonlinearality to improve the model's performance. `h_o` is the final layer, going from the hidden layer to the final output. \n",
    "The `forward` in pytorch takes in a batch of input data passed in by x. So the shape of x should be (batch_size, 3) because we only allowed the model to process three words. At least, in this simpler case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39773cd-351b-44cf-a6e6-9a8ad58dec52",
   "metadata": {},
   "source": [
    "In a recurrent neural network, there is a subtle difference in how we produce the activations. It's a linear process, but done with a loop: As we can see from the code, the first word of each batch was processed first. We'll break up the process step by step:\n",
    "\n",
    "- `x[:, 0]` selects the first word from every batch, making the tensor into the shape `(batch_size, 1)`.\n",
    "- `self.i_h(x[:,0])` uses the embedding matrix to replace the numericalized tokens into corresponding vectors, so the shape becomes `(batch_size, n_hidden)`. n_hidden is just another representation of the latent factors used in collaborative filtering.\n",
    "- `h = F.relu(self.h_h(self.i_h(x[:,0])))` turns the matrix into shape `(n_hidden, n_hidden)` and added relu for non-linearality.\n",
    "- then we add the activations of the second, third word in each of the batches, inserting relu between.\n",
    "- finally, `self.h_o(h)` is called to produce the output matrix.\n",
    "\n",
    "Overall, we use a weight matrix that is universal to all three words, but the final activations before a word are influenced by the words before it, in this way the model can take into account the order of the words in a sentence, not by adding the vectors of the word embeddings together.\n",
    "\n",
    "For the next piece of code, because the final activations are just predictions for each of the tokens, it can be treated the same way as image classification. So `cross_entropy` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86425aed-ca39-456b-9df9-3f648549fa80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.440551</td>\n",
       "      <td>1.438455</td>\n",
       "      <td>0.297314</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.426698</td>\n",
       "      <td>1.425912</td>\n",
       "      <td>0.301389</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.420663</td>\n",
       "      <td>1.420298</td>\n",
       "      <td>0.302786</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.418132</td>\n",
       "      <td>1.419128</td>\n",
       "      <td>0.302586</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, LMModel1(len(vocab), 64), loss_func=F.cross_entropy, \n",
    "                metrics=accuracy)\n",
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5580169-57cf-4678-965e-9177abb5a710",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2), 'buddha', 0.2601081081081081)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,counts = 0,torch.zeros(len(vocab))\n",
    "for x,y in dls.valid:\n",
    "    n += y.shape[0]\n",
    "    for i in range_of(vocab): counts[i] += (y==i).long().sum()\n",
    "idx = torch.argmax(counts)\n",
    "idx, vocab[idx.item()], counts[idx].item()/n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78937c9-8e5a-4c67-a80e-fa6e07775166",
   "metadata": {},
   "source": [
    "As we can see, the most common word is 'to', accounting for 22% of the total input tokens. So our result is way better!\n",
    "\n",
    "Here the logic of this piece of code needs to be further explained. We iterate through the `dls.valid` dataset, which gives us one batch at a time. `y` is a vector that contains 128 elements, corresponding to our `batch_size`. Then it is easy to understand that this is just a simple counting algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c9ad7b-3cc5-4156-83c5-d19cc33556b9",
   "metadata": {},
   "source": [
    "## Using a loop\n",
    "Now, instead of add the activations and applying `ReLU` by hand, we use a loop to automate the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "641bde50-1e0a-4019-9620-1bf8e7b0ed07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.212522</td>\n",
       "      <td>1.203242</td>\n",
       "      <td>0.371975</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.195914</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>0.369530</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.189458</td>\n",
       "      <td>1.183382</td>\n",
       "      <td>0.368815</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.186409</td>\n",
       "      <td>1.182275</td>\n",
       "      <td>0.372624</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LMModel2(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = 0\n",
    "        for i in range(6):\n",
    "            h = h + self.i_h(x[:,i])\n",
    "            h = F.relu(self.h_h(h))\n",
    "        return self.h_o(h)\n",
    "learn = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy, \n",
    "                metrics=accuracy)\n",
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29dbe9-83cd-4eaa-9798-559175f51411",
   "metadata": {},
   "source": [
    "## Adding detach\n",
    "A problem with our current model is that the hidden state `h` get set to zero every time it receives new outputs. This way, the neural network can only see the weird fragments of the real document, which is not good for our training. Now we set `h` to be a global variable in the class, this way the model can remember what it has seen in the past. \n",
    "\n",
    "However this creates another problem. The method we just decided to use makes our model really deep, and for each of these layers(there might be 10000 of them) we need to calculate the derivatives all from the start. The memory would explode! So we use the `detach` method in pytorch to only calculate the last three layers' derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ea3af53-ca58-4fe1-b034-a040106f8b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel3(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i in range(6):\n",
    "            self.h = self.h + self.i_h(x[:,i])\n",
    "            self.h = F.relu(self.h_h(self.h))\n",
    "        out = self.h_o(self.h)\n",
    "        self.h = self.h.detach()\n",
    "        return out\n",
    "    \n",
    "    def reset(self): self.h = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380086b-fded-438f-8493-82fd7bf96fb0",
   "metadata": {},
   "source": [
    "It is not an easy task to fully understand what `detach` is doing here. I will try my best to explain what's actually going on:\n",
    "- We do the regular forward propagation in the `forward` method. Then we called `self.h = self.h.detach()`.\n",
    "- Remember from the basic rules of deep learning, pytorch will automatically track the forward process and the calculation of the loss, forming a computation graph to get the derivatives for each parameter. If we don't cut the graph and allow the model to do millions of calculations to the hidden state `h`, then the computation graph would be extremely long, breaking the whole program.\n",
    "- So the graph should be cut into several small parts. For example, if we have 1000 words in total that need to be processed, without adding the `detach()`, then the last word will need to calculate 1000 layers of gradients. But what if after each time `forward` is called, we 'cut' the graph, so the process of calculating derivatives will stop there in future calculations? That's what `detach()` is doing!\n",
    "- When `detach()` is called, the previous gradients will not be affected. **It will only influence the backpropagations in the future, calculated by the next `forward` pass!** So each time we do `backward()`, the gradients will only be calculated along the last six layers, increasing the efficiency of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "55d30ef3-8c6d-40d3-91ba-1cf6b606040b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(\n",
    "    seqs, seqs_v, \n",
    "    bs=128, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "44e9975c-93e2-4add-b8f4-155d1fd6efc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.216328</td>\n",
       "      <td>1.203639</td>\n",
       "      <td>0.371385</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.202349</td>\n",
       "      <td>1.197370</td>\n",
       "      <td>0.371319</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.191182</td>\n",
       "      <td>1.185475</td>\n",
       "      <td>0.371069</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.187282</td>\n",
       "      <td>1.183284</td>\n",
       "      <td>0.372052</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, LMModel3(len(vocab), 64), loss_func=F.cross_entropy,\n",
    "                metrics=accuracy, cbs=ModelResetter)\n",
    "learn.fit_one_cycle(4, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702be728-89fe-449a-8447-780cf483562a",
   "metadata": {},
   "source": [
    "Note that there is no significant performance boost. Maybe only giving six tokens for our model to predict on is not enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b3794e-64b8-4cbf-bbb2-4e89adba904a",
   "metadata": {},
   "source": [
    "## Creating more signal\n",
    "We give eight tokens to the model for it to predict (or an arbitrary number bigger than the original one is acceptable). But first we need to introduce another method for data preparation: after adding the `detach()` method to our toolbox, the natural order of the sequence matters! And a big problem occurs with our current dataset: the first 128 items will be put in a batch, but they belong to the same part of the document, making them being processed by the neural network in parallel, thereby losing the order!\n",
    "\n",
    "So we need a way to transpose our sequence - making the model read them one by one. That's where `group_chunks` come in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "de50d595-9e37-47fd-bda8-ad59e6defdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_chunks(ds, bs):\n",
    "    m = len(ds) // bs\n",
    "    new_ds = L()\n",
    "    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n",
    "    return new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "104c64b2-21fd-4cf4-a76d-e519ff9316fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1000) [1,11,21,31,41,51,61,71,81,91,101,111,121,131,141,151,161,171,181,191...]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_chunks(list(range(1, 1001)), 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5615820-a8ce-475e-85f1-1094053f4c58",
   "metadata": {},
   "source": [
    "I'm using a simpler version of the input data to demonstrate. Suppose we have a sequence `[1, 2, ..., 1000]` that have a natural order, needing to be split to ten batches (which mean batch_size = 100). We don't want to split them into `[1, 2, ..., 100]`, `[101, 102, ..., 200]` and so forth, because this would lose useful information for our model. When we rearrange the list using `group_chunks`, the list is turned to `[1, 11, 21, ..., 991, 2, 12, ...]`. When processed as a batch, the natural order will be maintained.\n",
    "\n",
    "When using the previous models, the `group_chunks` method doen't add much performance boost. But now, it is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0898062c-60ed-4b5e-8f8d-34f52af76c07",
   "metadata": {},
   "source": [
    "Now we no longer need to use `drop_last=True` because the datasets are already normalized to a correct size for batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e00e9a0b-616d-45bc-b7f8-583a7612c13b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sl = 6\n",
    "seqs_mult = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+sl+1]))\n",
    "         for i in range(0,len(nums)-sl-1,sl))\n",
    "seqs_mult_v = L((tensor(nums_v[i:i+sl]), tensor(nums_v[i+1:i+sl+1]))\n",
    "         for i in range(0,len(nums_v)-sl-1,sl))\n",
    "dls = DataLoaders.from_dsets(group_chunks(seqs_mult, bs),\n",
    "                             group_chunks(seqs_mult_v, bs),\n",
    "                             bs=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88579ec2-44fa-4a81-8e81-30194d4f28a3",
   "metadata": {},
   "source": [
    "Also worth mentioning is that we did something different to the sequences. Not only we want the model to predict the next word after every three words, but to predict the next three words altogether. This requires a big change in our dataset and model, but the result is worth it. By giving more signal to our model, it has mores things to learn on, therefore getting better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3de3654b-545b-4cb1-ba16-f5d538f4476c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel4(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for i in range(sl):\n",
    "            self.h = self.h + self.i_h(x[:,i])\n",
    "            self.h = F.relu(self.h_h(self.h))\n",
    "            outs.append(self.h_o(self.h))\n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1)\n",
    "    \n",
    "    def reset(self): self.h = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d62ce-3e14-462d-a728-0e34118874be",
   "metadata": {},
   "source": [
    "There's a slight change to the `forward` function too. We store the hidden states during each iteration and force them to make a corresponding prediction, storing the total predictions in a list of length `sl`. Therefore the list `outs` after being stacked on `dim=1` becomes a tensor having a shape `(bs, sl, vocab_size)`, and to do cross entropy on a higher dimension needs a modified version of the loss function. Basically we flatten the tensor first, and then call the default `F.cross_entropy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6688ea6a-f689-43ff-a891-03136d473fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_func(inp, targ):\n",
    "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "add74412-232e-4ff0-845a-9fa1df95f78a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.585487</td>\n",
       "      <td>0.591583</td>\n",
       "      <td>0.683835</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.572355</td>\n",
       "      <td>0.574745</td>\n",
       "      <td>0.685032</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.569663</td>\n",
       "      <td>0.570365</td>\n",
       "      <td>0.684243</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.567611</td>\n",
       "      <td>0.569115</td>\n",
       "      <td>0.684288</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.567054</td>\n",
       "      <td>0.568130</td>\n",
       "      <td>0.684638</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, LMModel4(len(vocab), 64), loss_func=loss_func,\n",
    "                metrics=accuracy, cbs=ModelResetter)\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee676d6-fb57-45e3-9902-2dbe5e8cd4e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "This is a surprising accuracy!\n",
    "## Trying a multilayered RNN\n",
    "What we've actually changed here is using pytorch's default RNN framework, which basically does the same thing as our previous code, but allowing us to increase the depth of our RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ba2a8467-c7db-49fc-84d4-9a32cc69f022",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.578014</td>\n",
       "      <td>0.584330</td>\n",
       "      <td>0.684266</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.574130</td>\n",
       "      <td>0.577295</td>\n",
       "      <td>0.685140</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.569712</td>\n",
       "      <td>0.574084</td>\n",
       "      <td>0.685457</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.568163</td>\n",
       "      <td>0.571038</td>\n",
       "      <td>0.685151</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.567217</td>\n",
       "      <td>0.569991</td>\n",
       "      <td>0.684593</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LMModel5(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h = torch.zeros(n_layers, bs, n_hidden)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = h.detach()\n",
    "        return self.h_o(res)\n",
    "    \n",
    "    def reset(self): self.h.zero_()\n",
    "learn = Learner(dls, LMModel5(len(vocab), 64, 3), \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, cbs=ModelResetter)\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcc7b70-3ee8-437c-b955-04c5cd91833b",
   "metadata": {},
   "source": [
    "Sadly, this doesn't bring much difference to our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78860092-00ca-40e6-bf36-2570003bd27d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using LSTMs\n",
    "It's time to introduce a powerful tool: long-short term memeory!\n",
    "![1750573234874.png](https://img.picui.cn/free/2025/06/22/6857a0afa48b4.png)\n",
    "> First, the arrows for input and old hidden state are joined together. In the RNN we wrote earlier in this chapter, we were adding them together. In the LSTM, we stack them in one big tensor. This means the dimension of our embeddings (which is the dimension of $x_{t}$) can be different than the dimension of our hidden state. If we call those `n_in` and `n_hid`, the arrow at the bottom is of size `n_in + n_hid`; thus all the neural nets (orange boxes) are linear layers with `n_in + n_hid` inputs and `n_hid` outputs.\n",
    "\n",
    "> The first gate (looking from left to right) is called the *forget gate*. Since it’s a linear layer followed by a sigmoid, its output will consist of scalars between 0 and 1. We multiply this result by the cell state to determine which information to keep and which to throw away: values closer to 0 are discarded and values closer to 1 are kept. This gives the LSTM the ability to forget things about its long-term state. For instance, when crossing a period or an `xxbos` token, we would expect to it to (have learned to) reset its cell state.\n",
    "\n",
    "> The second gate is called the *input gate*. It works with the third gate (which doesn't really have a name but is sometimes called the *cell gate*) to update the cell state. For instance, we may see a new gender pronoun, in which case we'll need to replace the information about gender that the forget gate removed. Similar to the forget gate, the input gate decides which elements of the cell state to update (values close to 1) or not (values close to 0). The third gate determines what those updated values are, in the range of –1 to 1 (thanks to the tanh function). The result is then added to the cell state.\n",
    "\n",
    "> The last gate is the *output gate*. It determines which information from the cell state to use to generate the output. The cell state goes through a tanh before being combined with the sigmoid output from the output gate, and the result is the new hidden state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f34ad2-6f89-4d10-a49e-c5138a9e9607",
   "metadata": {},
   "source": [
    "Here's a simple implementation of the LSTM cell, which I'll thoroughly explain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8c610cec-20b7-4d5e-9f58-ea468c0d4fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMCell1(Module):\n",
    "    def __init__(self, ni, nh):\n",
    "        self.forget_gate = nn.Linear(ni + nh, nh)\n",
    "        self.input_gate  = nn.Linear(ni + nh, nh)\n",
    "        self.cell_gate   = nn.Linear(ni + nh, nh)\n",
    "        self.output_gate = nn.Linear(ni + nh, nh)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        h,c = state\n",
    "        h = torch.cat([h, input], dim=1)\n",
    "        forget = torch.sigmoid(self.forget_gate(h))\n",
    "        c = c * forget\n",
    "        inp = torch.sigmoid(self.input_gate(h))\n",
    "        cell = torch.tanh(self.cell_gate(h))\n",
    "        c = c + inp * cell\n",
    "        out = torch.sigmoid(self.output_gate(h))\n",
    "        h = out * torch.tanh(c)\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8854b-87a6-4baf-85ca-38fc22ce032c",
   "metadata": {},
   "source": [
    "- The inputs and states are stored or passed in separately, so we use `h,c = state`.\n",
    "- Following the instructions, we stack the hiddden state and inputs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "de93fc57-9b95-4841-87a1-aaf92c0141a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMCell(Module):\n",
    "    def __init__(self, ni, nh):\n",
    "        self.ih = nn.Linear(ni,4*nh)\n",
    "        self.hh = nn.Linear(nh,4*nh)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        h,c = state\n",
    "        # One big multiplication for all the gates is better than 4 smaller ones\n",
    "        gates = (self.ih(input) + self.hh(h)).chunk(4, 1)\n",
    "        ingate,forgetgate,outgate = map(torch.sigmoid, gates[:3])\n",
    "        cellgate = gates[3].tanh()\n",
    "\n",
    "        c = (forgetgate*c) + (ingate*cellgate)\n",
    "        h = outgate * c.tanh()\n",
    "        return h, (h,c)\n",
    "class LMModel6(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(res)\n",
    "    \n",
    "    def reset(self): \n",
    "        for h in self.h: h.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "738a387a-d8a9-48c7-af03-c1c2333cd7e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.575987</td>\n",
       "      <td>0.578387</td>\n",
       "      <td>0.685143</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.571813</td>\n",
       "      <td>0.574853</td>\n",
       "      <td>0.684710</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.569074</td>\n",
       "      <td>0.570702</td>\n",
       "      <td>0.685215</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.567799</td>\n",
       "      <td>0.569034</td>\n",
       "      <td>0.684810</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.567116</td>\n",
       "      <td>0.568250</td>\n",
       "      <td>0.684554</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, LMModel6(len(vocab), 128, 2), \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, cbs=ModelResetter)\n",
    "learn.fit_one_cycle(5, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616e392-ac14-4071-a23a-779347e90250",
   "metadata": {},
   "source": [
    "## Weight-tied Regularized LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "020b1a67-66b5-457e-b000-5e6ceb60a915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel7(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
    "        self.drop = nn.Dropout(p)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h_o.weight = self.i_h.weight\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        raw,h = self.rnn(self.i_h(x), self.h)\n",
    "        out = self.drop(raw)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(out),raw,out\n",
    "    \n",
    "    def reset(self): \n",
    "        for h in self.h: h.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b53d5995-ef9d-4163-a5ac-54d4e075a315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = TextLearner(dls, LMModel7(len(vocab), 64, 2, 0.4),\n",
    "                    loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2913f713-7bee-4fa3-b054-2ea0203dc862",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.577216</td>\n",
       "      <td>0.579187</td>\n",
       "      <td>0.684898</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.573831</td>\n",
       "      <td>0.572951</td>\n",
       "      <td>0.684896</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.570968</td>\n",
       "      <td>0.571168</td>\n",
       "      <td>0.685196</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.568685</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.684913</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.567818</td>\n",
       "      <td>0.568213</td>\n",
       "      <td>0.684796</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-2, wd=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
